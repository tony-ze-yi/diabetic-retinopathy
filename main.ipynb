{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models, datasets\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import collections\n",
    "from mpemu import mpt_emu\n",
    "from mpemu import qutils\n",
    "import timm\n",
    "\n",
    "# Define paths and hyperparameters\n",
    "BATCH_SIZE = 24\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "QUANTIZE = False\n",
    "TEST_MODEL = False\n",
    "\n",
    "# quantization\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# filter_module_types = [torch.nn.Conv2d, torch.nn.Linear] # Only quantizing convolution and linear modules\n",
    "# exempt_modules = [\"conv1\",\"fc\"]\n",
    "\n",
    "print()\n",
    "# define the EfficientNet models to use\n",
    "# b0 max: 64\n",
    "# b3 max: 32?\n",
    "efficientnets = {\n",
    "#     \"b0\": EfficientNet.from_pretrained(\"efficientnet-b0\", num_classes=5),\n",
    "    # \"b1\": EfficientNet.from_pretrained(\"efficientnet-b1\", num_classes=5),\n",
    "    # \"b2\": EfficientNet.from_pretrained(\"efficientnet-b2\", num_classes=5),\n",
    "    # \"b3\": EfficientNet.from_pretrained(\"efficientnet-b3\", num_classes=5),\n",
    "#     \"b4\": EfficientNet.from_pretrained(\"efficientnet-b4\", num_classes=5),\n",
    "    # \"b5\": EfficientNet.from_pretrained(\"efficientnet-b5\", num_classes=5),\n",
    "#     \"b6\": EfficientNet.from_pretrained(\"efficientnet-b6\", num_classes=5),\n",
    "#     \"b7\": EfficientNet.from_pretrained(\"efficientnet-b7\", num_classes=5),\n",
    "}\n",
    "\n",
    "efficientnet_sizes = {\n",
    "    \"b0\": 224,\n",
    "    \"b1\": 240,\n",
    "    \"b2\": 260,\n",
    "    \"b3\": 300,\n",
    "    \"b4\": 380,\n",
    "    \"b5\": 456,\n",
    "    \"b6\": 528,\n",
    "    \"b7\": 600,\n",
    "}\n",
    "model_name = 'vit_base_r50_s16_384'\n",
    "resnext = timm.create_model(model_name, pretrained=True, num_classes=5)\n",
    "models = [resnext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'maxvit_base_224',\n",
       " 'maxvit_large_224',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_224',\n",
       " 'maxvit_tiny_224',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_xlarge_224',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'semobilevit_s',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"*vit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:32<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5657, Acc: 0.8172\n",
      "Train time: 812.1566660404205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:13<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4922, Acc: 0.8391\n",
      "Val and misc time: 76.20014500617981\n",
      "Total time: 888.3565096855164\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:22<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4891, Acc: 0.8408\n",
      "Train time: 802.2055804729462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4876, Acc: 0.8424\n",
      "Val and misc time: 75.64579367637634\n",
      "Total time: 877.8510358333588\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:21<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4649, Acc: 0.8484\n",
      "Train time: 801.9409759044647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4676, Acc: 0.8464\n",
      "Val and misc time: 75.2134416103363\n",
      "Total time: 877.1541163921356\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4416, Acc: 0.8554\n",
      "Train time: 800.7629981040955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4718, Acc: 0.8457\n",
      "Val and misc time: 75.11421060562134\n",
      "Total time: 875.8769228458405\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4314, Acc: 0.8580\n",
      "Train time: 800.4915227890015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4736, Acc: 0.8428\n",
      "Val and misc time: 73.22255730628967\n",
      "Total time: 873.7137765884399\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:21<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4161, Acc: 0.8637\n",
      "Train time: 801.5804712772369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4571, Acc: 0.8514\n",
      "Val and misc time: 75.2109808921814\n",
      "Total time: 876.7911515235901\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3995, Acc: 0.8699\n",
      "Train time: 800.3165199756622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4558, Acc: 0.8520\n",
      "Val and misc time: 77.13170766830444\n",
      "Total time: 877.4479207992554\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:19<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3848, Acc: 0.8729\n",
      "Train time: 799.8281304836273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4662, Acc: 0.8512\n",
      "Val and misc time: 81.96287989616394\n",
      "Total time: 881.790717124939\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3727, Acc: 0.8745\n",
      "Train time: 800.1012840270996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4959, Acc: 0.8375\n",
      "Val and misc time: 85.59662938117981\n",
      "Total time: 885.6976172924042\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:21<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3509, Acc: 0.8840\n",
      "Train time: 801.1116940975189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4871, Acc: 0.8483\n",
      "Val and misc time: 76.6763608455658\n",
      "Total time: 877.7877683639526\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:19<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3336, Acc: 0.8900\n",
      "Train time: 799.7544877529144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4870, Acc: 0.8454\n",
      "Val and misc time: 75.17233347892761\n",
      "Total time: 874.9264996051788\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3129, Acc: 0.8938\n",
      "Train time: 800.6171128749847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.4852, Acc: 0.8512\n",
      "Val and misc time: 74.9721748828888\n",
      "Total time: 875.5889978408813\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:21<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2926, Acc: 0.9016\n",
      "Train time: 801.8886721134186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.5093, Acc: 0.8487\n",
      "Val and misc time: 75.56404614448547\n",
      "Total time: 877.4523930549622\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1163/1163 [13:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2760, Acc: 0.9056\n",
      "Train time: 800.011458158493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [01:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss: 0.5319, Acc: 0.8335\n",
      "Val and misc time: 73.40793108940125\n",
      "Total time: 873.4187347888947\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 631/1163 [07:15<06:05,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from lion_pytorch import Lion\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "def train():\n",
    "    # train the models and evaluate them on the validation set\n",
    "#     for model_name, model in efficientnets.items():\n",
    "    for model in models:\n",
    "        # define the transform for data augmentation and resizing\n",
    "#         image_size = efficientnet_sizes[model_name]\n",
    "        image_size=384\n",
    "        # Define data augmentations and transformations\n",
    "        train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        val_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                # transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Create train and validation datasets\n",
    "        dataset = datasets.ImageFolder(\"data_512\", transform=train_transforms)\n",
    "        dataset_val = datasets.ImageFolder(\"data_512\", transform=val_transforms)\n",
    "        print(dataset.classes)\n",
    "\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            list(range(len(dataset.targets))), test_size=0.2, stratify=dataset.targets\n",
    "        )\n",
    "        train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_dataset = torch.utils.data.Subset(dataset_val, val_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True\n",
    "        )\n",
    "\n",
    "        # Define model\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Lion(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        list_exempt_layers = [\"conv1\",\"fc\"]\n",
    "#         if \"resnet\" in args.arch or \"resnext\" in args.arch:\n",
    "#             list_exempt_layers = [\"conv1\",\"fc\"]\n",
    "#         elif args.arch == \"vgg19_bn\":\n",
    "#             list_exempt_layers = [\"features.0\", \"classifier.6\"]\n",
    "#         elif args.arch == \"inception_v3\":\n",
    "#             list_exempt_layers = [\"Conv2d_1a_3x3.conv\", \"fc\"]\n",
    "        \n",
    "        # quantization\n",
    "        if QUANTIZE:\n",
    "            model, emulator = mpt_emu.quantize_model(model, optimizer=optimizer, dtype=\"e4m3\", device=DEVICE, verbose=True, list_exempt_layers=list_exempt_layers, list_layers_output_fused=[])\n",
    "            emulator.set_default_inference_qconfig()\n",
    "#             filter_module_types = [torch.nn.Conv2d, torch.nn.Linear] # Only quantizing convolution and linear modules\n",
    "#             exempt_modules = [\"conv1\",\"fc\"]\n",
    "#             is_training = True\n",
    "#             wt_qconfig = qutils.TensorQuantConfig(\"e4m3\", \"rne\")#, \"per-channel\")\n",
    "#             iact_qconfig   = qutils.TensorQuantConfig(\"e4m3\", \"rne\")#, \"per-tensor\")\n",
    "#             emb_qconfig    = qutils.TensorQuantConfig(\"e4m3\", \"rne\")#, \"per-channel\")\n",
    "#             qconfig = qutils.ModuleQuantConfig(wt_qconfig=wt_qconfig, iact_qconfig=iact_qconfig)\n",
    "#             model_qconfig_dict  = qutils.get_or_update_model_quant_config_dict(model, filter_module_types, qconfig,\n",
    "#                                                                         exempt_modules=exempt_modules)\n",
    "#             print(\"Model quantization configuration\")\n",
    "#             for layer,qconfig in model_qconfig_dict.items():\n",
    "#                 print(layer, qconfig)\n",
    "#             print()\n",
    "            \n",
    "#             qutils.reset_quantization_setup(model, model_qconfig_dict)\n",
    "#             qhooks = qutils.add_quantization_hooks(model, model_qconfig_dict, is_training=is_training)\n",
    "        # test the model\n",
    "        if TEST_MODEL:\n",
    "            if QUANTIZE:\n",
    "                eval_model = emulator.fuse_bnlayers_and_quantize_model(model)\n",
    "            val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader):\n",
    "                    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                    if QUANTIZE:\n",
    "                        outputs = eval_model(images)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    val_acc += torch.sum(predictions == labels.data)\n",
    "            val_loss /= len(val_dataset)\n",
    "            val_acc /= len(val_dataset)\n",
    "            print(f\"Val   loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Train and validate the model\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            start = time.time()\n",
    "            start_total = time.time()\n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "            # Train the model\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "            for images, labels in tqdm(train_loader):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                train_acc += torch.sum(predictions == labels.data)\n",
    "            train_loss /= len(train_dataset)\n",
    "            train_acc /= len(train_dataset)\n",
    "            print(f\"Train loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "            print(f\"Train time: {time.time() - start}\")\n",
    "\n",
    "            start = time.time()\n",
    "            # Validate the model\n",
    "            if QUANTIZE:\n",
    "                eval_model = emulator.fuse_bnlayers_and_quantize_model(model)\n",
    "            val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader):\n",
    "                    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                    if QUANTIZE:\n",
    "                        outputs = eval_model(images)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    val_acc += torch.sum(predictions == labels.data)\n",
    "            val_loss /= len(val_dataset)\n",
    "            val_acc /= len(val_dataset)\n",
    "            print(f\"Val   loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            checkpoint_path = f\"checkpoint_{epoch+1}.pt\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_acc\": val_acc,\n",
    "                },\n",
    "                checkpoint_path,\n",
    "            )\n",
    "            total_end = time.time() - start_total\n",
    "\n",
    "            # Save loss and accuracy values to file\n",
    "            with open(\"loss_acc.txt\", \"a\") as file:\n",
    "                file.write(\n",
    "                    f\"{model_name}, {train_loss:.4f}, {train_acc:.4f}, {val_loss:.4f}, {val_acc:.4f}, {epoch}, {BATCH_SIZE}, {total_end}\\n\"\n",
    "                )\n",
    "\n",
    "            print(f\"Val and misc time: {time.time() - start}\")\n",
    "            print(f\"Total time: {total_end}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
